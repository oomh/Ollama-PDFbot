# Example environment configuration
# Copy this to .env and customize as needed

# PDF Processing
PDF_INPUT_DIR=data/sample_pdfs
PDF_OUTPUT_DIR=data/output
MAX_PAGES_PER_PDF=50

# LLM Configuration
# Available models: mistral, llama2, neural-chat, orca-mini, etc.
LLM_MODEL=llama3.2
LLM_BASE_URL=http://localhost:11434
LLM_TEMPERATURE=0.3

# Application Settings
BATCH_SIZE=5
LOG_LEVEL=INFO
GENERATE_INDEX=true
